{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8903857,"sourceType":"datasetVersion","datasetId":5353029},{"sourceId":11616346,"sourceType":"datasetVersion","datasetId":7286978},{"sourceId":11616541,"sourceType":"datasetVersion","datasetId":7287136}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"borhanitrash/animal-image-classification-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:43:40.791860Z","iopub.execute_input":"2025-04-29T16:43:40.792078Z","iopub.status.idle":"2025-04-29T16:43:43.128824Z","shell.execute_reply.started":"2025-04-29T16:43:40.792057Z","shell.execute_reply":"2025-04-29T16:43:43.128207Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/animal-image-classification-dataset\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n# Image dimensions and batch size\nimg_width, img_height = 150, 150\nbatch_size = 32\n\n# Data augmentation and preprocessing (same as before)\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/animal-image-classification-dataset/Animals',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/animal-image-classification-dataset/Animals',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation')\n\n# Load pre-trained VGG16 model (without the classification layers)\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n\n# Freeze the base model's layers \nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add new classification layers on top\nx = base_model.output\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)  # Add a dense layer\npredictions = Dense(train_generator.num_classes, activation='softmax')(x) # Output layer\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model (adjust epochs as needed)\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    epochs=10,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size)\n\n# Save the model\nmodel.save(\"animal_classifier_vgg16.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:17:07.593299Z","iopub.execute_input":"2025-04-29T17:17:07.594014Z","iopub.status.idle":"2025-04-29T17:18:57.730303Z","shell.execute_reply.started":"2025-04-29T17:17:07.593968Z","shell.execute_reply":"2025-04-29T17:18:57.729496Z"}},"outputs":[{"name":"stdout","text":"Found 2400 images belonging to 3 classes.\nFound 600 images belonging to 3 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 227ms/step - accuracy: 0.7175 - loss: 0.8762 - val_accuracy: 0.8663 - val_loss: 0.3449\nEpoch 2/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.3187\nEpoch 3/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 226ms/step - accuracy: 0.8865 - loss: 0.2618 - val_accuracy: 0.8906 - val_loss: 0.2966\nEpoch 4/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.3726\nEpoch 5/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 217ms/step - accuracy: 0.9260 - loss: 0.1766 - val_accuracy: 0.8906 - val_loss: 0.3164\nEpoch 6/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9167 - val_loss: 0.1654\nEpoch 7/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 212ms/step - accuracy: 0.9006 - loss: 0.2359 - val_accuracy: 0.8576 - val_loss: 0.4262\nEpoch 8/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7917 - val_loss: 0.7045\nEpoch 9/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 220ms/step - accuracy: 0.9255 - loss: 0.1797 - val_accuracy: 0.8958 - val_loss: 0.2856\nEpoch 10/10\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9583 - val_loss: 0.2351\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nimport os\n\n# Load the saved model\nmodel = tf.keras.models.load_model('/kaggle/working/animal_classifier_vgg16.h5')\n\n# Function to preprocess a single image\ndef preprocess_image(image_path, img_width=150, img_height=150):\n    img = image.load_img(image_path, target_size=(img_width, img_height))  # Resize image\n    img_array = image.img_to_array(img)  # Convert image to numpy array\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array /= 255.  # Rescale image\n    return img_array\n\n# Function to predict the class of a given image\ndef predict_image_class(image_path):\n    img_array = preprocess_image(image_path)\n    predictions = model.predict(img_array)  # Get prediction\n    predicted_class = np.argmax(predictions, axis=-1)  # Get the class index with highest probability\n    return predicted_class[0], predictions  # Return the predicted class index and probabilities\n\n# Example usage:\nimage_directory = '/kaggle/input/catsnake'  # Replace with your image directory\nimage_files = os.listdir(image_directory)\nimage_path = os.path.join(image_directory, image_files[0])  # Use the first image in the directory\n\nprint(f\"Using image path: {image_path}\")\n\n# Predict the class\npredicted_class, predictions = predict_image_class(image_path)\n\n# Get the class names from the training generator\nclass_names = list(train_generator.class_indices.keys())  # List of class names (e.g., 'cat', 'dog', 'snake')\n\n# Print the result\nprint(f\"Predicted class index: {predicted_class}\")\nprint(f\"Predicted class name: {class_names[predicted_class]}\")\nprint(f\"Prediction probabilities: {predictions}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:20:05.596860Z","iopub.execute_input":"2025-04-29T17:20:05.597428Z","iopub.status.idle":"2025-04-29T17:20:06.326123Z","shell.execute_reply.started":"2025-04-29T17:20:05.597407Z","shell.execute_reply":"2025-04-29T17:20:06.325390Z"}},"outputs":[{"name":"stdout","text":"Using image path: /kaggle/input/catsnake/snake.jpg\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step\nPredicted class index: 2\nPredicted class name: snakes\nPrediction probabilities: [[8.677103e-09 5.569593e-10 1.000000e+00]]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"list(train_generator.class_indices.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:07:03.990766Z","iopub.execute_input":"2025-04-29T17:07:03.991522Z","iopub.status.idle":"2025-04-29T17:07:03.996826Z","shell.execute_reply.started":"2025-04-29T17:07:03.991498Z","shell.execute_reply":"2025-04-29T17:07:03.996152Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['cats', 'dogs', 'snakes']"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}