{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd \nimport os\nimport cv2\nimport json\nimport ast\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import MobileNetV2, ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import MeanIoU\n\nos.makedirs('images', exist_ok=True)\nos.makedirs('masks', exist_ok=True)\n# data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_masks_from_coco(coco_json_path, images_dir, masks_dir):\n    with open(coco_json_path, 'r') as f:\n        data = json.load(f)\n\n    images_info = {img['id']: img for img in data['images']}\n    annotations_by_image = {}\n    for ann in data['annotations']:\n        annotations_by_image.setdefault(ann['image_id'], []).append(ann)\n\n    for img_id, info in images_info.items():\n        filename = info['file_name']\n        h, w = info['height'], info['width']\n        mask = np.zeros((h, w), dtype=np.uint8)\n\n        for ann in annotations_by_image.get(img_id, []):\n            cat = int(ann['category_id'])\n            for seg in ann['segmentation']:\n                polygon = np.array(seg, dtype=np.int32).reshape(-1, 2)\n                cv2.fillPoly(mask, [polygon], cat)\n\n        mask_name = os.path.splitext(filename)[0] + '_mask.png'\n        cv2.imwrite(os.path.join(masks_dir, mask_name), mask)\n\n# Example usage:\n# create_masks_from_coco('annotations.coco.json', 'images', 'masks')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_masks_from_csv(csv_path, images_dir, masks_dir):\n    df = pd.read_csv(csv_path)\n    groups = df.groupby('image_id')\n\n    for image_id, group in groups:\n        img_path = os.path.join(images_dir, image_id)\n        if not os.path.exists(img_path):\n            continue\n        img = cv2.imread(img_path)\n        h, w = img.shape[:2]\n        mask = np.zeros((h, w), dtype=np.uint8)\n\n        for _, row in group.iterrows():\n            seg = ast.literal_eval(row['segmentation'])\n            pts = np.array(seg, dtype=np.int32).reshape(-1, 2)\n            cv2.fillPoly(mask, [pts], color=int(row['category_id']))\n\n        mask_name = os.path.splitext(image_id)[0] + '_mask.png'\n        cv2.imwrite(os.path.join(masks_dir, mask_name), mask)\n\n# Example usage:\n# create_masks_from_csv('annotations.csv', 'images', 'masks')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data(img_dir, mask_dir, img_size=(256, 256)):\n    X, Y = [], []\n    for filename in os.listdir(img_dir):\n        img_path = os.path.join(img_dir, filename)\n        mask_path = os.path.join(mask_dir, os.path.splitext(filename)[0] + '_mask.png')\n        if os.path.exists(mask_path):\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, img_size)\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, img_size)\n            X.append(img)\n            Y.append(mask)\n\n    X, Y = np.array(X) / 255.0, np.expand_dims(np.array(Y), -1)\n    return X, Y\n\nX, Y = load_data('images', 'masks')\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet(input_shape):\n    inputs = layers.Input(input_shape)\n\n    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n    p1 = layers.MaxPooling2D(2)(c1)\n\n    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n    p2 = layers.MaxPooling2D(2)(c2)\n\n    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(c3)\n\n    u1 = layers.UpSampling2D(2)(c3)\n    u1 = layers.concatenate([u1, c2])\n    c4 = layers.Conv2D(128, 3, activation='relu', padding='same')(u1)\n\n    u2 = layers.UpSampling2D(2)(c4)\n    u2 = layers.concatenate([u2, c1])\n    c5 = layers.Conv2D(64, 3, activation='relu', padding='same')(u2)\n\n    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c5)\n\n    model = models.Model(inputs, outputs)\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet_backbone(backbone_model, input_shape):\n    inputs = layers.Input(shape=input_shape)\n    backbone = backbone_model(include_top=False, input_tensor=inputs)\n\n    skips = [backbone.get_layer(name).output for name in ['block_1_expand_relu', 'block_3_expand_relu', 'block_6_expand_relu', 'block_13_expand_relu']]\n    output = backbone.output\n\n    u = output\n    for skip in reversed(skips):\n        u = layers.UpSampling2D(2)(u)\n        u = layers.concatenate([u, skip])\n        u = layers.Conv2D(256, 3, activation='relu', padding='same')(u)\n\n    u = layers.UpSampling2D(2)(u)\n    outputs = layers.Conv2D(1, 1, activation='sigmoid')(u)\n    return models.Model(inputs, outputs)\n\nmobilenet_unet = unet_backbone(MobileNetV2, (256, 256, 3))\nresnet_unet = unet_backbone(ResNet50, (256, 256, 3))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compile_and_train(model, X_train, Y_train, X_val, Y_val, name):\n    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy', MeanIoU(num_classes=2)])\n    history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=8, epochs=20)\n    model.save(f'{name}.h5')\n    return history\n\nunet_model = unet((256, 256, 3))\ncompile_and_train(unet_model, X_train, Y_train, X_val, Y_val, 'unet_model')\ncompile_and_train(mobilenet_unet, X_train, Y_train, X_val, Y_val, 'mobilenet_unet')\ncompile_and_train(resnet_unet, X_train, Y_train, X_val, Y_val, 'resnet_unet')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Accuracy over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}