{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":737475,"sourceType":"datasetVersion","datasetId":379764},{"sourceId":2177371,"sourceType":"datasetVersion","datasetId":1307206},{"sourceId":10379798,"sourceType":"datasetVersion","datasetId":6429896}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **GAN is short form of Generative Adversarial Network** and a deep learning architecture. GAN consists of 2 parts, Discriminator and Generator.\n The Generator tries to creat fake images and fool the Discriminator, and Discriminator tries to distinguish the images and label them as fake(0) or real(1).\n\n This zero-sum game continuees until the Generator can no longer creat images which fools the Discriminator and the Discriminator cannot be fooled.\n\n There are different types of GAN Models but we are using DCGAN which is the short form of Deep Convolutional GAN.","metadata":{}},{"cell_type":"markdown","source":"# Step 1 | Importing librariesÂ¶\n","metadata":{}},{"cell_type":"code","source":"# tensorflow and keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D, Dropout, Reshape, Conv2DTranspose\nfrom tensorflow.keras.models import Sequential\nimport pathlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.metrics import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nimport os\nimport PIL\nimport time\nfrom IPython import display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:51:22.222838Z","iopub.execute_input":"2025-05-01T21:51:22.223036Z","iopub.status.idle":"2025-05-01T21:51:35.635045Z","shell.execute_reply.started":"2025-05-01T21:51:22.223017Z","shell.execute_reply":"2025-05-01T21:51:35.634478Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2 | Preparing data and showing some images\n","metadata":{}},{"cell_type":"code","source":"root_path = \"/kaggle/input/animefacedataset\"\nroot_path = pathlib.Path(root_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:51:35.636295Z","iopub.execute_input":"2025-05-01T21:51:35.636876Z","iopub.status.idle":"2025-05-01T21:51:35.640479Z","shell.execute_reply.started":"2025-05-01T21:51:35.636829Z","shell.execute_reply":"2025-05-01T21:51:35.639743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepraing data\nbatch_size = 128\n\ndata = keras.utils.image_dataset_from_directory(\n    directory=root_path,\n    label_mode=None,\n    batch_size=batch_size,\n    image_size=(64,64))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:51:35.641255Z","iopub.execute_input":"2025-05-01T21:51:35.641451Z","iopub.status.idle":"2025-05-01T21:54:05.662111Z","shell.execute_reply.started":"2025-05-01T21:51:35.641435Z","shell.execute_reply":"2025-05-01T21:54:05.661484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:05.662877Z","iopub.execute_input":"2025-05-01T21:54:05.663085Z","iopub.status.idle":"2025-05-01T21:54:05.668523Z","shell.execute_reply.started":"2025-05-01T21:54:05.663070Z","shell.execute_reply":"2025-05-01T21:54:05.667983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# let's see some images of the dataset\nplt.figure(figsize=(8,5))\nfor images in data.take(1):\n    for i in range(16):\n        ax = plt.subplot(4, 4, i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:05.670446Z","iopub.execute_input":"2025-05-01T21:54:05.670839Z","iopub.status.idle":"2025-05-01T21:54:06.565950Z","shell.execute_reply.started":"2025-05-01T21:54:05.670822Z","shell.execute_reply":"2025-05-01T21:54:06.565252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# normalizing the input image to the range [-1, 1]\ndata = data.map(lambda d : ((d-127.5)/127.5))\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:06.566723Z","iopub.execute_input":"2025-05-01T21:54:06.566991Z","iopub.status.idle":"2025-05-01T21:54:06.595451Z","shell.execute_reply.started":"2025-05-01T21:54:06.566970Z","shell.execute_reply":"2025-05-01T21:54:06.594723Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3 | Building Discriminator\nWhat is Discriminator ?\n\nThe Discriminator is a Neural Network model which tries to distinguish the real images from fake images(generated by Generator) and label them as fake(0) or real(1).\n\nNotes :\n\n1.The image size is (64,64), so the input_shape of first conv2d layer should be (64,64,3).\n\n2.The output of Discriminator is either a 0(fake) or 1(real).\n\n3.Using \"same\" as padding ensures us that the output dimension is not going to change.\n\n4.In the Discriminator function, all activations should be \"LeakyReLU\", exept the last layer which should be \"sigmoid\"\n\n5.The last layer is using \"sigmoid\" as activation function to create a binary output, which real images are labeled as 1 and the fake ones are labeled as 0.\n\nThe Discriminator downsamples the input shape.\nFirst let's build Discriminator function","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, BatchNormalization, Dropout, Flatten, Dense, LeakyReLU, Input\n\ndef Discriminator():\n    discriminator = Sequential()\n    discriminator.add(Input(shape=(64, 64, 3)))\n\n    discriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    discriminator.add(LeakyReLU(alpha=0.2))\n    discriminator.add(BatchNormalization())\n    discriminator.add(Dropout(0.2))\n\n    discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    discriminator.add(LeakyReLU(alpha=0.2))\n    discriminator.add(BatchNormalization())\n    discriminator.add(Dropout(0.2))\n\n    discriminator.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n    discriminator.add(LeakyReLU(alpha=0.2))\n    discriminator.add(BatchNormalization())\n    discriminator.add(Dropout(0.2))\n\n    discriminator.add(Flatten())\n    discriminator.add(Dropout(0.2))\n    discriminator.add(Dense(1, activation=\"sigmoid\"))\n\n    return discriminator\n\nD_model = Discriminator()\nD_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:06.596286Z","iopub.execute_input":"2025-05-01T21:54:06.596556Z","iopub.status.idle":"2025-05-01T21:54:07.460102Z","shell.execute_reply.started":"2025-05-01T21:54:06.596533Z","shell.execute_reply":"2025-05-01T21:54:07.459529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# optimizer\nD_optm = Adam(1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:07.460826Z","iopub.execute_input":"2025-05-01T21:54:07.461206Z","iopub.status.idle":"2025-05-01T21:54:07.469358Z","shell.execute_reply.started":"2025-05-01T21:54:07.461179Z","shell.execute_reply":"2025-05-01T21:54:07.468760Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"latent_dim = 100\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:07.470060Z","iopub.execute_input":"2025-05-01T21:54:07.470264Z","iopub.status.idle":"2025-05-01T21:54:07.475042Z","shell.execute_reply.started":"2025-05-01T21:54:07.470242Z","shell.execute_reply":"2025-05-01T21:54:07.474195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Reshape, BatchNormalization, Conv2DTranspose, Input, ReLU\nimport tensorflow as tf\n\nlatent_dim = 100  # Define your latent dimension\n\ndef Generator():\n    generator = Sequential()\n    generator.add(Input(shape=(latent_dim,)))  # Input is a latent vector\n    generator.add(Dense(4 * 4 * 256, use_bias=False))\n    generator.add(Reshape((4, 4, 256)))\n    generator.add(BatchNormalization())\n\n    generator.add(Conv2DTranspose(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\"))\n    generator.add(ReLU())\n    generator.add(BatchNormalization())\n\n    generator.add(Conv2DTranspose(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\"))\n    generator.add(ReLU())\n    generator.add(BatchNormalization())\n\n    generator.add(Conv2DTranspose(128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\"))\n    generator.add(ReLU())\n    generator.add(BatchNormalization())\n\n    generator.add(Conv2DTranspose(3, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", activation=\"tanh\"))\n\n    return generator\n\n# Create and view summary\nG_model = Generator()\nG_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:07.475787Z","iopub.execute_input":"2025-05-01T21:54:07.476056Z","iopub.status.idle":"2025-05-01T21:54:07.624393Z","shell.execute_reply.started":"2025-05-01T21:54:07.476035Z","shell.execute_reply":"2025-05-01T21:54:07.623826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# optimizer\nG_optm = Adam(1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:07.625068Z","iopub.execute_input":"2025-05-01T21:54:07.625282Z","iopub.status.idle":"2025-05-01T21:54:07.631021Z","shell.execute_reply.started":"2025-05-01T21:54:07.625266Z","shell.execute_reply":"2025-05-01T21:54:07.630476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating random noise\nrandom_noise = tf.random.normal([1,latent_dim])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:07.631844Z","iopub.execute_input":"2025-05-01T21:54:07.632198Z","iopub.status.idle":"2025-05-01T21:54:07.646856Z","shell.execute_reply.started":"2025-05-01T21:54:07.632179Z","shell.execute_reply":"2025-05-01T21:54:07.646344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# feeding random noise to Genereator\nG_output_on_random_noise = G_model(random_noise, training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:07.647561Z","iopub.execute_input":"2025-05-01T21:54:07.647722Z","iopub.status.idle":"2025-05-01T21:54:08.344418Z","shell.execute_reply.started":"2025-05-01T21:54:07.647710Z","shell.execute_reply":"2025-05-01T21:54:08.343612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# showing the image output of G_model\nplt.imshow(G_output_on_random_noise[0, :, :, 0])\nplt.axis(\"off\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.347218Z","iopub.execute_input":"2025-05-01T21:54:08.347422Z","iopub.status.idle":"2025-05-01T21:54:08.423593Z","shell.execute_reply.started":"2025-05-01T21:54:08.347407Z","shell.execute_reply":"2025-05-01T21:54:08.422864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# feeding the output of Generator to Discriminator\nD_output_on_random_noise = D_model(G_output_on_random_noise)\nprint(D_output_on_random_noise)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.424366Z","iopub.execute_input":"2025-05-01T21:54:08.424895Z","iopub.status.idle":"2025-05-01T21:54:08.795630Z","shell.execute_reply.started":"2025-05-01T21:54:08.424870Z","shell.execute_reply":"2025-05-01T21:54:08.794839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The code of this cell is from keras sample.\nclass GAN(tf.keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        # Sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n        # Decode them to fake images\n        generated_images = self.generator(seed)\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n\n        # Sample random points in the latent space\n        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n        \n        # Train the generator (note that we should *not* update the weights of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(seed))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.796508Z","iopub.execute_input":"2025-05-01T21:54:08.797096Z","iopub.status.idle":"2025-05-01T21:54:08.805935Z","shell.execute_reply.started":"2025-05-01T21:54:08.797071Z","shell.execute_reply":"2025-05-01T21:54:08.805292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GANCheckpoint(tf.keras.callbacks.Callback):\n    def __init__(self, generator, discriminator, save_dir=\"checkpoints\"):\n        super().__init__()\n        self.generator = generator\n        self.discriminator = discriminator\n        self.best_g_loss = float('inf')\n        self.best_d_loss = float('inf')\n        self.save_dir = save_dir\n        os.makedirs(save_dir, exist_ok=True)\n\n    def on_epoch_end(self, epoch, logs=None):\n        g_loss = logs[\"g_loss\"]\n        d_loss = logs[\"d_loss\"]\n\n        if g_loss < self.best_g_loss:\n            self.best_g_loss = g_loss\n            self.generator.save_weights(os.path.join(self.save_dir, \"best_generator.weights.h5\"))\n            print(f\"â Epoch {epoch}: Saved new best generator (g_loss: {g_loss:.4f})\")\n\n        if d_loss < self.best_d_loss:\n            self.best_d_loss = d_loss\n            self.discriminator.save_weights(os.path.join(self.save_dir, \"best_discriminator.weights.h5\"))\n            print(f\"â Epoch {epoch}: Saved new best discriminator (d_loss: {d_loss:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.806653Z","iopub.execute_input":"2025-05-01T21:54:08.807156Z","iopub.status.idle":"2025-05-01T21:54:08.823556Z","shell.execute_reply.started":"2025-05-01T21:54:08.807133Z","shell.execute_reply":"2025-05-01T21:54:08.822961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# loss function\nloss_fn = tf.keras.losses.BinaryCrossentropy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.824271Z","iopub.execute_input":"2025-05-01T21:54:08.824442Z","iopub.status.idle":"2025-05-01T21:54:08.839668Z","shell.execute_reply.started":"2025-05-01T21:54:08.824429Z","shell.execute_reply":"2025-05-01T21:54:08.839017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = GAN(discriminator=D_model, generator=G_model, latent_dim=latent_dim)\nmodel.compile(d_optimizer=D_optm, g_optimizer=G_optm, loss_fn=loss_fn)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.840403Z","iopub.execute_input":"2025-05-01T21:54:08.840605Z","iopub.status.idle":"2025-05-01T21:54:08.874902Z","shell.execute_reply.started":"2025-05-01T21:54:08.840590Z","shell.execute_reply":"2025-05-01T21:54:08.874372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# Callbacks\ncheckpoint_cb = GANCheckpoint(generator=G_model, discriminator=D_model, save_dir=\"checkpoints\")\n\n# Training\nhistory = model.fit(\n    data,\n    epochs=100,\n    callbacks=[checkpoint_cb]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T21:54:08.875663Z","iopub.execute_input":"2025-05-01T21:54:08.875888Z","iopub.status.idle":"2025-05-01T22:26:11.701481Z","shell.execute_reply.started":"2025-05-01T21:54:08.875873Z","shell.execute_reply":"2025-05-01T22:26:11.700733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# creating a random nosie to feed it to the trained Generator model\nnoise = tf.random.normal([32, 100])\n# Generatine new images using the trained Generator model \ngenerated_images = G_model(noise, training=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T22:26:11.702422Z","iopub.execute_input":"2025-05-01T22:26:11.702656Z","iopub.status.idle":"2025-05-01T22:26:11.742501Z","shell.execute_reply.started":"2025-05-01T22:26:11.702631Z","shell.execute_reply":"2025-05-01T22:26:11.741964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# converting the input image to the range [0, 255]\ngenerated_images1 = (generated_images+127.5)*127.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T22:26:11.743311Z","iopub.execute_input":"2025-05-01T22:26:11.743575Z","iopub.status.idle":"2025-05-01T22:26:11.748225Z","shell.execute_reply.started":"2025-05-01T22:26:11.743552Z","shell.execute_reply":"2025-05-01T22:26:11.747451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i+1)\n    plt.imshow(generated_images1[i].numpy().astype(\"uint8\"))\n    plt.axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T22:26:11.748985Z","iopub.execute_input":"2025-05-01T22:26:11.749238Z","iopub.status.idle":"2025-05-01T22:26:12.105369Z","shell.execute_reply.started":"2025-05-01T22:26:11.749217Z","shell.execute_reply":"2025-05-01T22:26:12.104719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}